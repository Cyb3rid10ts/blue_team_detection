{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MalURL Detector\n",
    "**Authors:** Alistair Gillespie & Veatrissa Lim \n",
    "---\n",
    "### Introduction\n",
    "Here lies a classification model that aims to predict the maliciousnes of any given URL. The notebook is a collection of data cleaning, feature engineering and modelling steps, that combine to deliver the MalURL Detector. The model is based on a set of reputational and lexical features. Currently, the MalURL detector uses an ensemble of decision trees (i.e. a random forest)\n",
    "\n",
    "**Status**: 19/05/2019 - Currently working on additional features and model tuning. In addition, to sourcing new training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Sections              | Description   |\n",
    "| :---------------------|:---------------|\n",
    "| Introduction         | Introduction to the MalURL Detector |\n",
    "| Setup                | Import foundational and machine learning libraries |\n",
    "| Data Ingestion       | Ingest and clean the URL and IANA data sets    |\n",
    "| Feature Engineering  | Extract and engineer the set of reputational and lexical features|\n",
    "| Modeling             | Train and tune the Random Forest classifier, then make some predictions |\n",
    "\n",
    "\n",
    "Next steps:\n",
    "* Consider new reputational features i.e. last updated\n",
    "* Use binary encoding for categorical features rather than Label Encoder\n",
    "* Conduct further model tuning and deepen understanding of Random Forest and other candidate classifiers\n",
    "* Handling of unseen values in test phase i.e. categorical features and encodings\n",
    "* More to come..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# GENERAL\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "# SKLEARN\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, f1_score ,recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "# DOMAIN SPECIFIC LIBRARIES\n",
    "import tldextract\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from urllib.parse import urlparse\n",
    "from socket import gethostbyname, gaierror\n",
    "import whois\n",
    "\n",
    "# iPython and Notebook config\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" #display all results\n",
    "%config InlineBackend.figure_format = 'retina' #see plots in retina displays\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setup utilities for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def creation_date(domain_name):\n",
    "    \"\"\"\n",
    "    Gets creation date of domain\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get creation date of Domain \n",
    "    domain_name = whois.whois(domain_name).creation_date\n",
    "    \n",
    "    # Handling exceptions\n",
    "    if type(domain_name) is list:\n",
    "        return domain_name[0]\n",
    "    elif str(domain_name).find('Aug'):\n",
    "        domain_name = \"1996-07-01 00:00:01\"\n",
    "        return domain_name\n",
    "    elif domain_name == np.nan:\n",
    "        currentDT = datetime.now()\n",
    "        domain_name = currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return domain_name\n",
    "    else:\n",
    "        return domain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countSpecial(x):\n",
    "    \"\"\"\n",
    "    Counts number of special characters in a string\n",
    "    \"\"\"\n",
    "    new = re.sub('[\\w]+' ,'', x)\n",
    "    return len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(string):\n",
    "    \"\"\"\n",
    "    Calculates the Shannon entropy of a string\n",
    "    \"\"\"\n",
    "\n",
    "    # Get probability of chars in string\n",
    "    prob = [ float(string.count(c)) / len(string) for c in dict.fromkeys(list(string)) ]\n",
    "\n",
    "    # Calculate the entropy\n",
    "    entropy = - sum([ p * math.log(p) / math.log(2.0) for p in prob ])\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def host_ip(domain):\n",
    "    \"\"\"\n",
    "    Gets Host IP of Domain\n",
    "    \"\"\"\n",
    "\n",
    "    # Get HOST IP     \n",
    "    try:\n",
    "        host = gethostbyname(domain)\n",
    "        return host\n",
    "    except gaierror:\n",
    "        return 'missing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_domain_parts(df, feature_col):\n",
    "    \"\"\"\n",
    "    Extract domain components\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract domain\n",
    "    df['domain'] = df[feature_col].apply(lambda x: tldextract.extract(x).domain)\n",
    "    \n",
    "    # Extract suffix\n",
    "    df['suffix'] = df[feature_col].apply(lambda x: tldextract.extract(x).suffix)\n",
    "    \n",
    "    # Extract suffix\n",
    "    df['domain_name'] = df[feature_col].apply(lambda x: tldextract.extract(x).registered_domain)\n",
    "    \n",
    "    # TODO - Handle null domain and suffix\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_host_ip(df, domain_col):\n",
    "    \"\"\"\n",
    "    Gets host IP address associated with domain\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract Host IP \n",
    "    df['host_ip'] = df[domain_col].apply(lambda x: host_ip(x))\n",
    "    \n",
    "    # TODO - Handle null hosts\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prefix(df, host_col):\n",
    "    \"\"\"\n",
    "    Gets first octet of IP\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract prefix, first octet\n",
    "    df['prefix'] = df[host_col].str.extract('(\\d+)\\.').astype(int, errors='ignore').astype(str)\n",
    "    df['prefix'] = df['prefix'].fillna('missing')\n",
    "    df['prefix'] = df['prefix'].replace('nan', 'missing')\n",
    "    \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_creation_date(df, feature_col):\n",
    "    \"\"\"\n",
    "    Gets creation date of domain\n",
    "    \"\"\"\n",
    "    \n",
    "    df['domain_creation'] = df[feature_col].apply(lambda x: creation_date(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_domain_age(df, creation_col):\n",
    "    \"\"\"\n",
    "    Calculates the age of the domain in days\n",
    "    \"\"\"\n",
    "      \n",
    "    # Cast domain age columnt to datetime\n",
    "    df[creation_col] = pd.to_datetime(df[creation_col], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Calculate the age of the domain\n",
    "    df['domain_age'] = pd.datetime.today().date() - df[creation_col].dt.date\n",
    "    \n",
    "    # Cast age to an integer\n",
    "    df['domain_age'] = df['domain_age'].astype(str).str.extract(\"(\\d+)\").astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_domain_entropy(df, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates entropy of a feature for a given data set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate entropy \n",
    "    df['entropy'] = df[feature_col].apply(lambda x: entropy(str(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_suffix(df, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates number of suffix in the URL\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculates number of suffix in the URL\n",
    "    df['number_suffix'] = df[feature_col].str.count('\\.')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_digits(df, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates number of numerical characters in a string\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculates number of digits\n",
    "    df['number_digits'] = df[feature_col].str.count('[0-9]')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_percent_digits(df):\n",
    "    \"\"\"\n",
    "    Calculates percentage of string is a digit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate percentage\n",
    "    df['digits_percentage'] = (df['number_digits']/df['string_length'])*100\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_string_length(df, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates length of string\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculates length of string\n",
    "    df['string_length'] = df[feature_col].str.len()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_specials(df, feature_col):\n",
    "    \"\"\"\n",
    "    Calculates number of special characters in string\n",
    "    \"\"\"\n",
    "    \n",
    "    # Count of special characters\n",
    "    df['specials'] = df[feature_col].apply(lambda x: countSpecial(str(x)))\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iana_designations(df, iana, prefix_col):\n",
    "    \"\"\"\n",
    "    Merges data sets on the prefix i.e. first octect of the IPv4 address\n",
    "    \"\"\"\n",
    "\n",
    "    # Enrich sample with IPv4 Registry data\n",
    "    df = df.merge(iana, on=prefix_col, how='left')\n",
    "\n",
    "    # Clean prefix and drop unneeded columns\n",
    "    df['prefix'] = df['prefix'].astype(str)\n",
    "    df['designation'] = df['designation'].fillna('missing')\n",
    "    df.rename(columns={ 'status [1]': 'status'}, inplace=True)\n",
    "    df.drop(['note'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction_train(data, iana_data):\n",
    "    \"\"\"\n",
    "    Pipeline utility for extracting all candidate functions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assumes string or dataframe input\n",
    "    \n",
    "    # Handle string or dataframe input\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        df = pd.DataFrame(data=[data], columns=['url']) # Create dataframe from string  \n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    # Conduct extraction\n",
    "    print('  * Loading features')\n",
    "    df = get_domain_entropy(df, 'domain_name') # Extract domain entropy\n",
    "    df[df['domain_creation'] == str]\n",
    "    df = get_domain_age(df, 'domain_creation') # Extract domain age\n",
    "    df = get_number_suffix(df, 'domain_name') # Extract number of suffix\n",
    "    df = get_number_digits(df, 'domain_name') # Extract number of digits\n",
    "    df = get_string_length(df, 'domain_name') # Extract string length\n",
    "    df = get_percent_digits(df) # Extract percentage digits\n",
    "    df = get_specials(df, 'domain_name') # Extract number of specials\n",
    "    df = get_iana_designations(df, iana_data,'prefix') # Extract designation\n",
    "    \n",
    "    print('  * Number of features extracted: ' + str(len(df.columns.tolist())))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction_prod(data, iana_data):\n",
    "    \"\"\"\n",
    "    Pipeline utility for extracting all candidate functions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assumes string or dataframe input\n",
    "    \n",
    "    # Handle string or dataframe input\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        df = pd.DataFrame(data=[data], columns=['url']) # Create dataframe from string  \n",
    "    else:\n",
    "        df = data\n",
    "    \n",
    "    # Conduct extraction\n",
    "    print('  * Loading features')\n",
    "    df = get_domain_parts(df, 'url') # Extract domain parts\n",
    "    df = get_creation_date(df, 'domain_name') # Extract domain creation date\n",
    "    df = get_domain_age(df, 'domain_creation') # Extract domain age\n",
    "    df = get_domain_entropy(df, 'domain_name') # Extract domain entropy       \n",
    "    df = get_number_suffix(df, 'domain_name') # Extract number of suffix\n",
    "    df = get_number_digits(df, 'domain_name') # Extract number of digits\n",
    "    df = get_string_length(df, 'domain_name') # Extract string length\n",
    "    df = get_percent_digits(df) # Extract percentage digits\n",
    "    df = get_specials(df, 'domain_name') # Extract number of specials\n",
    "    df = get_host_ip(df, 'domain_name') # Extract host IP\n",
    "    df = get_prefix(df, 'host_ip') # Extract prefix\n",
    "    df = get_iana_designations(df, iana_data,'prefix') # Extract designation\n",
    "    \n",
    "    print('  * Number of features extracted: ' + str(len(df.columns.tolist())))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering_train(df): \n",
    "    \"\"\"\n",
    "    Conduct encoding, normalisation and standardisation of features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup Label Encoders\n",
    "    suffix_le = LabelEncoder()\n",
    "    designation_le = LabelEncoder()\n",
    "    prefix_le = LabelEncoder()\n",
    "\n",
    "    # Fit labels and transform data\n",
    "    df['suffix'] = suffix_le.fit_transform(df['suffix'])\n",
    "    df['designation'] = designation_le.fit_transform(df['designation'])\n",
    "    df['prefix'] = prefix_le.fit_transform(df['prefix'])\n",
    "    \n",
    "    # Save encodings\n",
    "    np.save('suffix.npy', suffix_le.classes_)\n",
    "    np.save('designation.npy', designation_le.classes_)\n",
    "    np.save('prefix.npy', prefix_le.classes_)\n",
    "    \n",
    "    # Setup min max scaler for dense variables\n",
    "    mms = MinMaxScaler()\n",
    "    \n",
    "    # Fit distributions and transform data\n",
    "    df[['entropy', 'domain_age']] = mms.fit_transform(df[['entropy', 'domain_age']])\n",
    "    \n",
    "    # Save Min Max models\n",
    "    joblib.dump(mms, 'mms.pkl')\n",
    "    \n",
    "    # Setup Max Abs scaler for sparse variables\n",
    "    mas = MaxAbsScaler()\n",
    "    \n",
    "    # Fit distributions and transform data\n",
    "    num_features = ['number_digits', 'string_length','digits_percentage', \n",
    "                    'specials', 'number_suffix']\n",
    "    df[num_features] = mas.fit_transform(df[num_features])\n",
    "    \n",
    "    # Save Max Abs models\n",
    "    joblib.dump(mas, 'mas.pkl')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def feature_engineering_prod(df): \n",
    "    \"\"\"\n",
    "    Conduct encoding, normalisation and standardisation of features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup Label Encoders\n",
    "    suffix_le = LabelEncoder()\n",
    "    designation_le = LabelEncoder()\n",
    "    prefix_le = LabelEncoder()\n",
    "    \n",
    "    # Load encodings\n",
    "    suffix_le.classes_ = np.load('suffix.npy', allow_pickle=True)\n",
    "    designation_le.classes_ = np.load('designation.npy', allow_pickle=True)\n",
    "    prefix_le.classes_ = np.load('prefix.npy', allow_pickle=True)\n",
    "    \n",
    "    # Get integer mappings\n",
    "    integer_mapping = {l: i for i, l in enumerate(prefix_le.classes_)}\n",
    "    \n",
    "    # Transform categorical variables\n",
    "    # If prefix exists already, then transform\n",
    "    if df['prefix'].isin(integer_mapping).any():\n",
    "        # If value is in mapping list, transform\n",
    "        prefix_le.transform(df[['prefix']])\n",
    "        print('  * Value successfully transformed.') \n",
    "    \n",
    "    # Else value is not in mapping list, add to mapping list and transform\n",
    "    else:\n",
    "        prefix_le.classes_ = np.append(prefix_le.classes_, df['prefix'].iloc[0:1])\n",
    "        prefix_le.transform(df.prefix)\n",
    "        print('  * New unseen value added to label encoder.')\n",
    "\n",
    "    df[['suffix']] = suffix_le.transform(df[['suffix']])\n",
    "    df[['designation']] = designation_le.transform(df[['designation']])\n",
    "    \n",
    "    # Load MinMax models\n",
    "    mms = joblib.load('mms.pkl')\n",
    "    \n",
    "    # Transform min max features\n",
    "    df[['entropy', 'domain_age']] = mms.transform(df[['entropy', 'domain_age']])\n",
    "    \n",
    "    # Load Max Abs models\n",
    "    mas =joblib.load('mas.pkl')\n",
    "    \n",
    "    num_features = ['number_digits', 'string_length','digits_percentage', \n",
    "                    'specials', 'number_suffix']\n",
    "    \n",
    "    # Transform Max Abs features\n",
    "    df[num_features] = mas.transform(df[num_features])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(df, features, test_percentage, class_weight): \n",
    "    \"\"\"\n",
    "    Train model\n",
    "    \"\"\"\n",
    "\n",
    "    # Grab feature set for model\n",
    "    feature_df = df[features].copy()\n",
    "    \n",
    "    # Label target\n",
    "    target_le = LabelEncoder()\n",
    "    feature_df['label'] = target_le.fit_transform(feature_df['label'])\n",
    "    \n",
    "    # Split target and features\n",
    "    X = feature_df.loc[:, feature_df.columns != 'label']\n",
    "    y = feature_df['label']\n",
    "    \n",
    "    # Train and Test split\n",
    "    print('  * Performing cross-validation') \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percentage, random_state=42)\n",
    "    \n",
    "    # Parameters for Grid Search\n",
    "    param_grid = {\n",
    "        'min_samples_split': [3, 5, 10], \n",
    "        'n_estimators' : [100, 300],\n",
    "        'max_depth': [3, 5, 15, 25],\n",
    "        'max_features': [3, 5, 10, 20]\n",
    "    }\n",
    "    \n",
    "    # Scoring for Grid Search\n",
    "    scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score)\n",
    "    }\n",
    "    \n",
    "    # Setup base Classifier and Grid Search\n",
    "    print('  * Initiating Malicious URL Model') \n",
    "    clf = RandomForestClassifier()\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    rdf = GridSearchCV(clf, param_grid, scoring=scorers, refit='precision_score',\n",
    "                       cv=skf, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    # Fit model\n",
    "    print('  * Training Malicious URL Model') \n",
    "    rdf.fit(X_train, y_train);\n",
    "    \n",
    "    # Run predictions\n",
    "    print('  * Predicting test classes')     \n",
    "    rfprediction = rdf.predict(X_test)  # predict output\n",
    "\n",
    "    # Calculate accuracy \n",
    "    print('\\n\\n')\n",
    "    print('  * Performance testing:')\n",
    "    print(\"    Precision - %1.3f\" % precision_score(y_test, rfprediction))\n",
    "    print(\"    Recall - %1.3f\" % recall_score(y_test, rfprediction))\n",
    "    print(\"    F1 - %1.3f\\n\" % f1_score(y_test, rfprediction))\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true=y_test, y_pred=rfprediction)\n",
    "    print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "    labels = ['Benign', 'Malicious']\n",
    "    fig = plt.figure();\n",
    "    ax = fig.add_subplot(111);\n",
    "    cax = ax.matshow(conf_mat, cmap=plt.cm.Reds);\n",
    "    fig.colorbar(cax);\n",
    "    ax.set_xticklabels([''] + labels);\n",
    "    ax.set_yticklabels([''] + labels);\n",
    "    plt.xlabel('Predicted');\n",
    "    plt.ylabel('Expected');\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(rdf, 'malicious_url_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_maliciousness(url, features):\n",
    "    \"\"\"\n",
    "    Predict maliciousness of URL\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model\n",
    "    model = joblib.load('malicious_url_model.pkl')\n",
    "    \n",
    "    # Extract features\n",
    "    url_features = feature_extraction_prod(url, iana)\n",
    "    \n",
    "    # Engineer features\n",
    "    url_features = feature_engineering_prod(url_features)\n",
    "    \n",
    "    # Produce features and score\n",
    "    score = str(model.predict_proba(url_features[features]).tolist()[0][1])\n",
    "    return [url_features, score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106156 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_name</th>\n",
       "      <th>domain</th>\n",
       "      <th>suffix</th>\n",
       "      <th>label</th>\n",
       "      <th>domain_creation</th>\n",
       "      <th>IP</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yothreedot.com</td>\n",
       "      <td>yothreedot</td>\n",
       "      <td>com</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2012-05-10 19:35:01</td>\n",
       "      <td>184.168.221.37</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sukop.com</td>\n",
       "      <td>sukop</td>\n",
       "      <td>com</td>\n",
       "      <td>malicious</td>\n",
       "      <td>1999-03-03 05:00:00</td>\n",
       "      <td>66.33.210.251</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manage-updates43.gotdns.ch</td>\n",
       "      <td>gotdns</td>\n",
       "      <td>ch</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2019-05-19 10:17:20</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unisupport-confrim5.cf</td>\n",
       "      <td>unisupport-confrim5</td>\n",
       "      <td>cf</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2019-05-19 10:17:20</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unblocking-fb-help.usa.cc</td>\n",
       "      <td>usa</td>\n",
       "      <td>cc</td>\n",
       "      <td>malicious</td>\n",
       "      <td>1997-10-12 04:00:00</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain_name               domain suffix      label  \\\n",
       "0              yothreedot.com           yothreedot    com  malicious   \n",
       "1                   sukop.com                sukop    com  malicious   \n",
       "2  manage-updates43.gotdns.ch               gotdns     ch  malicious   \n",
       "3      unisupport-confrim5.cf  unisupport-confrim5     cf  malicious   \n",
       "4   unblocking-fb-help.usa.cc                  usa     cc  malicious   \n",
       "\n",
       "       domain_creation              IP   prefix  \n",
       "0  2012-05-10 19:35:01  184.168.221.37    184.0  \n",
       "1  1999-03-03 05:00:00   66.33.210.251     66.0  \n",
       "2  2019-05-19 10:17:20         0.0.0.0      0.0  \n",
       "3  2019-05-19 10:17:20         missing  missing  \n",
       "4  1997-10-12 04:00:00         missing  missing  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingest sample dataset\n",
    "df = pd.read_csv(\"9072018_batch_sample_intensive\", sep=',')\n",
    "\n",
    "# Cleaning tasks\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df['prefix'] = pd.to_numeric(df['prefix'], downcast='float').astype(str)\n",
    "\n",
    "# Clean missing dates\n",
    "currentDT = datetime.now()\n",
    "dt_now = currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "df['domain_creation'] = df['domain_creation'].fillna(dt_now)\n",
    "\n",
    "# Clean old dates\n",
    "older_dt = \"1996-07-01 00:00:01\"\n",
    "df.loc[df['domain_creation'].str.contains('Aug'), 'domain_creation'] = older_dt\n",
    "\n",
    "# Clean missing prefix\n",
    "df['prefix'] = df['prefix'].fillna('missing')\n",
    "df['prefix'] = df['prefix'].replace('nan', 'missing')\n",
    "\n",
    "# Clean missing hosts\n",
    "df['IP'] = df['IP'].fillna('missing')\n",
    "df['suffix'] = df['suffix'].fillna('missing')\n",
    "\n",
    "# Get rid of numbered suffix entries\n",
    "df = df[~df['suffix'].str.contains('\\d')]\n",
    "\n",
    "print(str(df.shape[0]) + \" samples\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>designation</th>\n",
       "      <th>date</th>\n",
       "      <th>whois</th>\n",
       "      <th>rdap</th>\n",
       "      <th>status [1]</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>IANA - Local Identification</td>\n",
       "      <td>1981-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RESERVED</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>APNIC</td>\n",
       "      <td>2010-01</td>\n",
       "      <td>whois.apnic.net</td>\n",
       "      <td>https://rdap.apnic.net/</td>\n",
       "      <td>ALLOCATED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RIPE NCC</td>\n",
       "      <td>2009-09</td>\n",
       "      <td>whois.ripe.net</td>\n",
       "      <td>https://rdap.db.ripe.net/</td>\n",
       "      <td>ALLOCATED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Administered by ARIN</td>\n",
       "      <td>1994-05</td>\n",
       "      <td>whois.arin.net</td>\n",
       "      <td>https://rdap.arin.net/registry\\nhttp://rdap.ar...</td>\n",
       "      <td>LEGACY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Level 3 Parent, LLC</td>\n",
       "      <td>1992-12</td>\n",
       "      <td>whois.arin.net</td>\n",
       "      <td>https://rdap.arin.net/registry\\nhttp://rdap.ar...</td>\n",
       "      <td>LEGACY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                  designation     date            whois  \\\n",
       "0    0.0  IANA - Local Identification  1981-09              NaN   \n",
       "1    1.0                        APNIC  2010-01  whois.apnic.net   \n",
       "2    2.0                     RIPE NCC  2009-09   whois.ripe.net   \n",
       "3    3.0         Administered by ARIN  1994-05   whois.arin.net   \n",
       "4    4.0          Level 3 Parent, LLC  1992-12   whois.arin.net   \n",
       "\n",
       "                                                rdap status [1] note  \n",
       "0                                                NaN   RESERVED  [2]  \n",
       "1                            https://rdap.apnic.net/  ALLOCATED  NaN  \n",
       "2                          https://rdap.db.ripe.net/  ALLOCATED  NaN  \n",
       "3  https://rdap.arin.net/registry\\nhttp://rdap.ar...     LEGACY  NaN  \n",
       "4  https://rdap.arin.net/registry\\nhttp://rdap.ar...     LEGACY  NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingest IANA dataset\n",
    "iana = pd.read_csv(\"https://www.iana.org/assignments/ipv4-address-space/ipv4-address-space.csv\", sep=\",\")\n",
    "iana.columns = iana.columns.str.strip().str.lower()\n",
    "iana.rename(columns={'Prefix': 'prefix'}, inplace=True)\n",
    "\n",
    "# Clean up prefix since it uses old/BSD formatting\n",
    "iana['prefix']= iana['prefix'].apply(lambda x: re.sub('^(00|0)','',x))\n",
    "iana['prefix'] = iana['prefix'].apply(lambda x: re.sub('/8$','',x))\n",
    "iana['prefix'] = pd.to_numeric(iana['prefix'], downcast='float',errors='ignore').astype(str)\n",
    "\n",
    "print(str(iana.shape[0]) + \" samples\")\n",
    "\n",
    "iana.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 7 columns.\n",
      "There are 1 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Missing Values  % of Total Values\n",
       "domain              11                0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "benign       74939\n",
       "malicious    31217\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_values_table(df)\n",
    "\n",
    "# Check classes\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Loading features\n",
      "  * Number of features extracted: 19\n",
      "CPU times: user 3.9 s, sys: 62.3 ms, total: 3.97 s\n",
      "Wall time: 3.84 s\n",
      "CPU times: user 809 ms, sys: 176 ms, total: 985 ms\n",
      "Wall time: 248 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_name</th>\n",
       "      <th>domain</th>\n",
       "      <th>suffix</th>\n",
       "      <th>label</th>\n",
       "      <th>domain_creation</th>\n",
       "      <th>IP</th>\n",
       "      <th>prefix</th>\n",
       "      <th>entropy</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>number_suffix</th>\n",
       "      <th>number_digits</th>\n",
       "      <th>string_length</th>\n",
       "      <th>digits_percentage</th>\n",
       "      <th>specials</th>\n",
       "      <th>designation</th>\n",
       "      <th>date</th>\n",
       "      <th>whois</th>\n",
       "      <th>rdap</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yothreedot.com</td>\n",
       "      <td>yothreedot</td>\n",
       "      <td>172</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2012-05-10 19:35:01</td>\n",
       "      <td>184.168.221.37</td>\n",
       "      <td>91</td>\n",
       "      <td>0.590953</td>\n",
       "      <td>0.204285</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-12</td>\n",
       "      <td>whois.arin.net</td>\n",
       "      <td>https://rdap.arin.net/registry\\nhttp://rdap.ar...</td>\n",
       "      <td>ALLOCATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sukop.com</td>\n",
       "      <td>sukop</td>\n",
       "      <td>172</td>\n",
       "      <td>malicious</td>\n",
       "      <td>1999-03-03 05:00:00</td>\n",
       "      <td>66.33.210.251</td>\n",
       "      <td>167</td>\n",
       "      <td>0.538475</td>\n",
       "      <td>0.587926</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>whois.arin.net</td>\n",
       "      <td>https://rdap.arin.net/registry\\nhttp://rdap.ar...</td>\n",
       "      <td>ALLOCATED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manage-updates43.gotdns.ch</td>\n",
       "      <td>gotdns</td>\n",
       "      <td>127</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2019-05-19 10:17:20</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10</td>\n",
       "      <td>1981-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RESERVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unisupport-confrim5.cf</td>\n",
       "      <td>unisupport-confrim5</td>\n",
       "      <td>125</td>\n",
       "      <td>malicious</td>\n",
       "      <td>2019-05-19 10:17:20</td>\n",
       "      <td>missing</td>\n",
       "      <td>202</td>\n",
       "      <td>0.714176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unblocking-fb-help.usa.cc</td>\n",
       "      <td>usa</td>\n",
       "      <td>119</td>\n",
       "      <td>malicious</td>\n",
       "      <td>1997-10-12 04:00:00</td>\n",
       "      <td>missing</td>\n",
       "      <td>202</td>\n",
       "      <td>0.768267</td>\n",
       "      <td>0.628305</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  domain_name               domain  suffix      label  \\\n",
       "0              yothreedot.com           yothreedot     172  malicious   \n",
       "1                   sukop.com                sukop     172  malicious   \n",
       "2  manage-updates43.gotdns.ch               gotdns     127  malicious   \n",
       "3      unisupport-confrim5.cf  unisupport-confrim5     125  malicious   \n",
       "4   unblocking-fb-help.usa.cc                  usa     119  malicious   \n",
       "\n",
       "      domain_creation              IP  prefix   entropy  domain_age  \\\n",
       "0 2012-05-10 19:35:01  184.168.221.37      91  0.590953    0.204285   \n",
       "1 1999-03-03 05:00:00   66.33.210.251     167  0.538475    0.587926   \n",
       "2 2019-05-19 10:17:20         0.0.0.0       0  0.769485    0.000000   \n",
       "3 2019-05-19 10:17:20         missing     202  0.714176    0.000000   \n",
       "4 1997-10-12 04:00:00         missing     202  0.768267    0.628305   \n",
       "\n",
       "   number_suffix  number_digits  string_length  digits_percentage  specials  \\\n",
       "0       0.047619       0.000000       0.058824           0.000000  0.033333   \n",
       "1       0.047619       0.000000       0.037815           0.000000  0.033333   \n",
       "2       0.095238       0.016807       0.109244           0.096154  0.100000   \n",
       "3       0.047619       0.008403       0.092437           0.056818  0.066667   \n",
       "4       0.095238       0.000000       0.105042           0.000000  0.133333   \n",
       "\n",
       "   designation     date           whois  \\\n",
       "0            2  2008-12  whois.arin.net   \n",
       "1            2  2000-07  whois.arin.net   \n",
       "2           10  1981-09             NaN   \n",
       "3           19      NaN             NaN   \n",
       "4           19      NaN             NaN   \n",
       "\n",
       "                                                rdap     status  \n",
       "0  https://rdap.arin.net/registry\\nhttp://rdap.ar...  ALLOCATED  \n",
       "1  https://rdap.arin.net/registry\\nhttp://rdap.ar...  ALLOCATED  \n",
       "2                                                NaN   RESERVED  \n",
       "3                                                NaN        NaN  \n",
       "4                                                NaN        NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features\n",
    "%time train_test_df = feature_extraction_train(df, iana)\n",
    "\n",
    "# Engineer features\n",
    "%time train_test_df = feature_engineering_train(train_test_df)\n",
    "\n",
    "train_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Performing cross-validation\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "features = ['label', 'domain_age', 'entropy', 'suffix', 'designation', 'number_suffix', 'digits_percentage', 'specials']\n",
    "\n",
    "# Test size\n",
    "test_percentage = 0.2\n",
    "\n",
    "# Class weight\n",
    "# Options: \n",
    "# dict({0:1, 1:7})\n",
    "# 'balanced'\n",
    "class_weight ='balanced'\n",
    "\n",
    "train_model(train_test_df, features, test_percentage, class_weight)\n",
    "\n",
    "# Candidates  =  'whois', 'status', 'suffix' ,'entropy', 'designation',  'number_suffix', 'non_alphanumeric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define features\n",
    "mal_features = ['domain_age', 'entropy', 'suffix', 'designation', 'number_suffix', 'digits_percentage', 'specials']\n",
    "    \n",
    "# User to predict maliciousness\n",
    "url = 'https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle?'\n",
    "\n",
    "# Example urls 'xiazai1.wan4399.com', 'xcl168.s37.jjisp.com'\n",
    "print('Initiating Malicious URL Classifier:')\n",
    "\n",
    "# Produce output\n",
    "malURL_output = predict_maliciousness(url, mal_features)\n",
    "\n",
    "# Display features and score\n",
    "display(malURL_output[0])\n",
    "print(\"\\n\\n\\n [\" + url + \"] maliciousness score: \" + malURL_output[1])\n",
    "\n",
    "# Considerations:\n",
    "# - urls with hyphens"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
